{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPucUj9Y9KTIxXTaTnBogGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FS75/wo-ai-AI/blob/feature%2Ftext-language-translation/dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNimv8dCcjpf"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn transformers sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    return {'hello': 'world'}"
      ],
      "metadata": {
        "id": "Rk3jCMkieLaQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer_en_zh = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-zh\")\n",
        "model_en_zh = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-zh\")\n",
        "\n",
        "tokenizer_zh_en = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
        "model_zh_en = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")"
      ],
      "metadata": {
        "id": "cEWsr1S4nmfW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to translate text from English to Chinese\n",
        "def translate_en_to_zh(text):\n",
        "    input_ids = tokenizer_en_zh.encode(text, return_tensors=\"pt\")\n",
        "    outputs = model_en_zh.generate(\n",
        "        input_ids,\n",
        "        max_length=50,               # Limits the length of the output sequence\n",
        "        num_beams=10,                # Uses beam search decoding to improve output quality\n",
        "        no_repeat_ngram_size=2,      # Prevents the model from repeating the same n-grams\n",
        "        early_stopping=True,         # Stops generation when all beam candidates reach the end token\n",
        "        repetition_penalty=1.2,      # Penalizes repeating words to ensure diversity in output\n",
        "        do_sample=True,              # Enables sampling to introduce randomness into output predictions\n",
        "        temperature=0.2              # Lowers the temperature for more conservative and likely outputs\n",
        "    )\n",
        "    translated_text = tokenizer_en_zh.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_text\n",
        "\n",
        "\n",
        "# Function to translate text from Chinese to English\n",
        "def translate_zh_to_en(text):\n",
        "    # Tokenize the text\n",
        "    input_ids = tokenizer_zh_en.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the translated output using advanced parameters\n",
        "    outputs = model_zh_en.generate(\n",
        "        input_ids,\n",
        "        max_length=50,               # Limits the length of the output sequence\n",
        "        num_beams=10,                # Uses beam search decoding to improve output quality\n",
        "        no_repeat_ngram_size=2,      # Prevents the model from repeating the same n-grams\n",
        "        early_stopping=True,         # Stops generation when all beam candidates reach the end token\n",
        "        repetition_penalty=1.2,      # Penalizes repeating words to ensure diversity in output\n",
        "        do_sample=True,              # Enables sampling to introduce randomness into output predictions\n",
        "        temperature=0.2              # Lowers the temperature for more conservative and likely outputs\n",
        "    )\n",
        "\n",
        "    # Decode and return the translated text\n",
        "    translated_text = tokenizer_zh_en.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_text\n",
        "\n",
        "@app.get('/en-to-ch')\n",
        "async def english_to_chinese(en_text):\n",
        "  try:\n",
        "    translated_text = translate_en_to_zh(en_text)\n",
        "\n",
        "    return translated_text\n",
        "\n",
        "  except Exception as e:\n",
        "    return JSONResponse((str(e)))\n",
        "\n",
        "@app.get('/ch-to-en')\n",
        "async def chinese_to_english(ch_text):\n",
        "    try:\n",
        "      translated_text = translate_en_to_zh(ch_text)\n",
        "\n",
        "      return translated_text\n",
        "\n",
        "    except Exception as e:\n",
        "      return JSONResponse((str(e)))"
      ],
      "metadata": {
        "id": "IAyr4QLTqhlT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from google.colab import userdata\n",
        "ngrok_auth = userdata.get(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "ngrok.set_auth_token(ngrok_auth)\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "api_url = ngrok_tunnel.public_url\n",
        "print('Public URL:', api_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "id": "0AKyB0gfeL7Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}